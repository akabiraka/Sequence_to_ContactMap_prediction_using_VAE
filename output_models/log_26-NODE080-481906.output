device= cuda
batch_size= 40
n_epochs= 100
init_lr= 1e-07
loss=BCE(sum) + 3*KLD
BasicVAE1(
  (fc1): Linear(in_features=64, out_features=20, bias=True)
  (encoder): Sequential(
    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 1024, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (9): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc2): Linear(in_features=1024, out_features=512, bias=True)
  (fc31): Linear(in_features=512, out_features=50, bias=True)
  (fc32): Linear(in_features=512, out_features=50, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): Sigmoid()
  )
  (fc4): Linear(in_features=50, out_features=512, bias=True)
  (fc5): Linear(in_features=512, out_features=1024, bias=True)
  (relu): ReLU()
)
loading training dataset ... ...
900  proteins in hand
train dataset len:  308360
train loader size:  7709
successfully loaded training dataset ... ...
loading validation dataset ... ...
300  proteins in hand
val dataset len: 111784
val loader size:  2795
successfully loaded validation dataset ... ...
Starting epoch 1/101
epoch:1/101, train_loss: 32641.4960938
learning rate:  1e-07
Starting epoch 2/101
epoch:2/101, train_loss: 30086.8613281
learning rate:  1e-07
Starting epoch 3/101
epoch:3/101, train_loss: 29717.8964844
learning rate:  1e-07
Starting epoch 4/101
epoch:4/101, train_loss: 29628.5703125
learning rate:  1e-07
Starting testing epoch 4/101
epoch:4/101, val_loss: 29614.6132812
Updating best val loss: 29614.6132812
Starting epoch 5/101
epoch:5/101, train_loss: 29595.1132812
learning rate:  1e-07
Starting epoch 6/101
epoch:6/101, train_loss: 29576.7773438
learning rate:  1e-07
Starting epoch 7/101
epoch:7/101, train_loss: 29564.3964844
learning rate:  1e-07
Starting epoch 8/101
epoch:8/101, train_loss: 29555.3867188
learning rate:  1e-07
Starting testing epoch 8/101
epoch:8/101, val_loss: 29557.7988281
Updating best val loss: 29557.7988281
Starting epoch 9/101
epoch:9/101, train_loss: 29548.3476562
learning rate:  1e-07
Starting epoch 10/101
epoch:10/101, train_loss: 29542.7246094
learning rate:  1e-07
Starting epoch 11/101
epoch:11/101, train_loss: 29536.9375000
learning rate:  1e-07
Starting epoch 12/101
epoch:12/101, train_loss: 29480.4609375
learning rate:  1e-07
Starting testing epoch 12/101
epoch:12/101, val_loss: 29482.7500000
Updating best val loss: 29482.7500000
Starting epoch 13/101
epoch:13/101, train_loss: 29475.4453125
learning rate:  1e-07
Starting epoch 14/101
epoch:14/101, train_loss: 29472.3476562
learning rate:  1e-07
Starting epoch 15/101
epoch:15/101, train_loss: 29469.7988281
learning rate:  1e-07
Starting epoch 16/101
epoch:16/101, train_loss: 29467.6660156
learning rate:  1e-07
Starting testing epoch 16/101
epoch:16/101, val_loss: 29472.0898438
Updating best val loss: 29472.0898438
Starting epoch 17/101
epoch:17/101, train_loss: 29465.8359375
learning rate:  1e-07
Starting epoch 18/101
epoch:18/101, train_loss: 29464.2695312
learning rate:  1e-07
Starting epoch 19/101
epoch:19/101, train_loss: 29462.9316406
learning rate:  1e-07
Starting epoch 20/101
epoch:20/101, train_loss: 29461.7832031
learning rate:  1e-07
Starting testing epoch 20/101
epoch:20/101, val_loss: 29466.5722656
Updating best val loss: 29466.5722656
Starting epoch 21/101
epoch:21/101, train_loss: 29383.9687500
learning rate:  1e-07
Starting epoch 22/101
epoch:22/101, train_loss: 29293.6933594
learning rate:  1e-07
Starting epoch 23/101
epoch:23/101, train_loss: 29292.1699219
learning rate:  1e-07
Starting epoch 24/101
epoch:24/101, train_loss: 29291.2929688
learning rate:  1e-07
Starting testing epoch 24/101
epoch:24/101, val_loss: 29294.4296875
Updating best val loss: 29294.4296875
Starting epoch 25/101
epoch:25/101, train_loss: 29290.6171875
learning rate:  1e-07
Starting epoch 26/101
epoch:26/101, train_loss: 29290.0468750
learning rate:  1e-07
Starting epoch 27/101
epoch:27/101, train_loss: 29289.5605469
learning rate:  1e-07
Starting epoch 28/101
epoch:28/101, train_loss: 29289.1484375
learning rate:  1e-07
Starting testing epoch 28/101
epoch:28/101, val_loss: 29292.4316406
Updating best val loss: 29292.4316406
Starting epoch 29/101
epoch:29/101, train_loss: 29267.0683594
learning rate:  1e-07
Starting epoch 30/101
epoch:30/101, train_loss: 29121.8613281
learning rate:  1e-07
Starting epoch 31/101
epoch:31/101, train_loss: 29120.8652344
learning rate:  1e-07
Starting epoch 32/101
epoch:32/101, train_loss: 29079.7558594
learning rate:  1e-07
Starting testing epoch 32/101
epoch:32/101, val_loss: 29066.4257812
Updating best val loss: 29066.4257812
Starting epoch 33/101
epoch:33/101, train_loss: 29064.3476562
learning rate:  1e-07
Starting epoch 34/101
epoch:34/101, train_loss: 29064.0664062
learning rate:  1e-07
Starting epoch 35/101
epoch:35/101, train_loss: 29063.8691406
learning rate:  1e-07
Starting epoch 36/101
epoch:36/101, train_loss: 29063.7089844
learning rate:  1e-07
Starting testing epoch 36/101
epoch:36/101, val_loss: 29065.5078125
Updating best val loss: 29065.5078125
Starting epoch 37/101
epoch:37/101, train_loss: 29063.5761719
learning rate:  1e-07
Starting epoch 38/101
epoch:38/101, train_loss: 29063.4628906
learning rate:  1e-07
Starting epoch 39/101
epoch:39/101, train_loss: 29063.3671875
learning rate:  1e-07
Starting epoch 40/101
epoch:40/101, train_loss: 29063.2851562
learning rate:  1e-07
Starting testing epoch 40/101
epoch:40/101, val_loss: 29065.1074219
Updating best val loss: 29065.1074219
Starting epoch 41/101
epoch:41/101, train_loss: 29063.2167969
learning rate:  1e-07
Starting epoch 42/101
epoch:42/101, train_loss: 29053.7832031
learning rate:  1e-07
Starting epoch 43/101
epoch:43/101, train_loss: 28880.4960938
learning rate:  1e-07
Starting epoch 44/101
epoch:44/101, train_loss: 28764.7304688
learning rate:  1e-07
Starting testing epoch 44/101
epoch:44/101, val_loss: 28762.7734375
Updating best val loss: 28762.7734375
Starting epoch 45/101
epoch:45/101, train_loss: 28764.1621094
learning rate:  1e-07
Starting epoch 46/101
epoch:46/101, train_loss: 28764.0234375
learning rate:  1e-07
Starting epoch 47/101
epoch:47/101, train_loss: 28763.9589844
learning rate:  1e-07
Starting epoch 48/101
epoch:48/101, train_loss: 28763.9140625
learning rate:  1e-07
Starting testing epoch 48/101
epoch:48/101, val_loss: 28762.3457031
Updating best val loss: 28762.3457031
Starting epoch 49/101
epoch:49/101, train_loss: 28760.9804688
learning rate:  1e-07
Starting epoch 50/101
epoch:50/101, train_loss: 28726.5078125
learning rate:  1e-07
Starting epoch 51/101
epoch:51/101, train_loss: 28726.4140625
learning rate:  1e-07
Starting epoch 52/101
epoch:52/101, train_loss: 28726.3808594
learning rate:  1e-07
Starting testing epoch 52/101
epoch:52/101, val_loss: 28724.5898438
Updating best val loss: 28724.5898438
Starting epoch 53/101
epoch:53/101, train_loss: 28726.3613281
learning rate:  1e-07
Starting epoch 54/101
epoch:54/101, train_loss: 28726.3437500
learning rate:  1e-07
Starting epoch 55/101
epoch:55/101, train_loss: 28726.3320312
learning rate:  1e-07
Starting epoch 56/101
epoch:56/101, train_loss: 28726.3183594
learning rate:  1e-07
Starting testing epoch 56/101
epoch:56/101, val_loss: 28724.5273438
Updating best val loss: 28724.5273438
Starting epoch 57/101
epoch:57/101, train_loss: 28726.3085938
learning rate:  1e-07
Starting epoch 58/101
epoch:58/101, train_loss: 28726.3027344
learning rate:  1e-07
Starting epoch 59/101
epoch:59/101, train_loss: 28726.2968750
learning rate:  1e-07
Starting epoch 60/101
epoch:60/101, train_loss: 28710.8574219
learning rate:  1e-07
Starting testing epoch 60/101
epoch:60/101, val_loss: 28556.6738281
Updating best val loss: 28556.6738281
Starting epoch 61/101
epoch:61/101, train_loss: 28558.5136719
learning rate:  1e-07
Starting epoch 62/101
epoch:62/101, train_loss: 28558.3710938
learning rate:  1e-07
Starting epoch 63/101
epoch:63/101, train_loss: 28558.3476562
learning rate:  1e-07
Starting epoch 64/101
epoch:64/101, train_loss: 28478.0312500
learning rate:  1e-07
Starting testing epoch 64/101
epoch:64/101, val_loss: 28387.3964844
Updating best val loss: 28387.3964844
Starting epoch 65/101
epoch:65/101, train_loss: 28391.3867188
learning rate:  1e-07
Starting epoch 66/101
epoch:66/101, train_loss: 28391.3378906
learning rate:  1e-07
Starting epoch 67/101
epoch:67/101, train_loss: 28391.3281250
learning rate:  1e-07
Starting epoch 68/101
epoch:68/101, train_loss: 28391.3222656
learning rate:  1e-07
Starting testing epoch 68/101
epoch:68/101, val_loss: 28387.2597656
Updating best val loss: 28387.2597656
Starting epoch 69/101
epoch:69/101, train_loss: 28391.3203125
learning rate:  1e-07
Starting epoch 70/101
epoch:70/101, train_loss: 28391.3203125
learning rate:  1e-07
Starting epoch 71/101
epoch:71/101, train_loss: 28391.3203125
learning rate:  1e-07
Starting epoch 72/101
epoch:72/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 72/101
epoch:72/101, val_loss: 28387.2539062
Updating best val loss: 28387.2539062
Starting epoch 73/101
epoch:73/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 74/101
epoch:74/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 75/101
epoch:75/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 76/101
epoch:76/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 76/101
epoch:76/101, val_loss: 28387.2500000
Updating best val loss: 28387.2500000
Starting epoch 77/101
epoch:77/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 78/101
epoch:78/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 79/101
epoch:79/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 80/101
epoch:80/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 80/101
epoch:80/101, val_loss: 28387.2500000
Starting epoch 81/101
epoch:81/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 82/101
epoch:82/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 83/101
epoch:83/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 84/101
epoch:84/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 84/101
epoch:84/101, val_loss: 28387.2500000
Starting epoch 85/101
epoch:85/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 86/101
epoch:86/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 87/101
epoch:87/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 88/101
epoch:88/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 88/101
epoch:88/101, val_loss: 28387.2500000
Starting epoch 89/101
epoch:89/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 90/101
epoch:90/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 91/101
epoch:91/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 92/101
epoch:92/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 92/101
epoch:92/101, val_loss: 28387.2500000
Starting epoch 93/101
epoch:93/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 94/101
epoch:94/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 95/101
epoch:95/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 96/101
epoch:96/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 96/101
epoch:96/101, val_loss: 28387.2500000
Starting epoch 97/101
epoch:97/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 98/101
epoch:98/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 99/101
epoch:99/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting epoch 100/101
epoch:100/101, train_loss: 28391.3164062
learning rate:  1e-07
Starting testing epoch 100/101
epoch:100/101, val_loss: 28387.2500000
[32641.49609375, 30086.861328125, 29717.896484375, 29628.5703125, 29595.11328125, 29576.77734375, 29564.396484375, 29555.38671875, 29548.34765625, 29542.724609375, 29536.9375, 29480.4609375, 29475.4453125, 29472.34765625, 29469.798828125, 29467.666015625, 29465.8359375, 29464.26953125, 29462.931640625, 29461.783203125, 29383.96875, 29293.693359375, 29292.169921875, 29291.29296875, 29290.6171875, 29290.046875, 29289.560546875, 29289.1484375, 29267.068359375, 29121.861328125, 29120.865234375, 29079.755859375, 29064.34765625, 29064.06640625, 29063.869140625, 29063.708984375, 29063.576171875, 29063.462890625, 29063.3671875, 29063.28515625, 29063.216796875, 29053.783203125, 28880.49609375, 28764.73046875, 28764.162109375, 28764.0234375, 28763.958984375, 28763.9140625, 28760.98046875, 28726.5078125, 28726.4140625, 28726.380859375, 28726.361328125, 28726.34375, 28726.33203125, 28726.318359375, 28726.30859375, 28726.302734375, 28726.296875, 28710.857421875, 28558.513671875, 28558.37109375, 28558.34765625, 28478.03125, 28391.38671875, 28391.337890625, 28391.328125, 28391.322265625, 28391.3203125, 28391.3203125, 28391.3203125, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625, 28391.31640625]
[29614.61328125, 29557.798828125, 29482.75, 29472.08984375, 29466.572265625, 29294.4296875, 29292.431640625, 29066.42578125, 29065.5078125, 29065.107421875, 28762.7734375, 28762.345703125, 28724.58984375, 28724.52734375, 28556.673828125, 28387.396484375, 28387.259765625, 28387.25390625, 28387.25, 28387.25, 28387.25, 28387.25, 28387.25, 28387.25, 28387.25]
